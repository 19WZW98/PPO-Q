{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install imageio",
   "id": "d436195b12d3b69f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from model.utils import setup_training\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from model.models import DiscreteActor"
   ],
   "id": "c08c8a1988f42770"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Configuration and weight paths\n",
    "config_path = '../config/CartPole.yaml'  # Path to the configuration file\n",
    "weight_path = 'your weight path'  # Path to the pre-trained model weights\n",
    "\n",
    "# Set the device to CUDA if available, otherwise use CPU\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "id": "810bbe9c292a6802"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = setup_training(config_path)\n",
    "\n",
    "env = gym.make(args.env_name, render_mode=\"rgb_array\")\n",
    "observation, info = env.reset(seed=args.seed)\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "actor = DiscreteActor(n_wires=args.n_wires,\n",
    "                                       n_blocks=args.n_blocks,\n",
    "                                       input_dim=args.state_dim,\n",
    "                                       output_dim=args.action_dim,\n",
    "                                       ini_method=args.ini_method).to(DEVICE)\n",
    "\n",
    "actor.load_state_dict(torch.load(weight_path))  # # Load the pre-trained model weights"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "frames = []\n",
    "\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "while not done:\n",
    "    frame = env.render()\n",
    "    frames.append(frame)\n",
    "\n",
    "    s = torch.tensor(observation, dtype=torch.float32, device=DEVICE).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dist = Categorical(probs=actor(s))\n",
    "        action = dist.sample().cpu().item()\n",
    "\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    total_reward += reward\n",
    "\n",
    "env.close()\n",
    "print(f\"Total Reward: {total_reward}\")\n"
   ],
   "id": "1b1e03499fc9718b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save the recorded frames as a GIF\n",
    "gif_path = \"env_inference.gif\"\n",
    "imageio.mimsave(gif_path, frames, fps=30)"
   ],
   "id": "bb2c83f8e10370c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Display the GIF in Jupyter Notebook\n",
    "from IPython.display import Image\n",
    "Image(gif_path)"
   ],
   "id": "a2fd6ce8a30e584a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
